{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "explore_BERT_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e939d87a13e244d79f00b20e7df1226c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f24c935d459b46a79df971d59b46d2a6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b37e724bd8f94c11850984955d7b36a2",
              "IPY_MODEL_a49a23512fc344579b9a3a535f76ddde"
            ]
          }
        },
        "f24c935d459b46a79df971d59b46d2a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b37e724bd8f94c11850984955d7b36a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a5efece2d6d64d7f971964c8b3d28a84",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_020a51198b734d4ba693a7e906e8fee9"
          }
        },
        "a49a23512fc344579b9a3a535f76ddde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_585e6bdcbe32407182e861df3a2835bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 574kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4514582da26401a9836b63db0d51500"
          }
        },
        "a5efece2d6d64d7f971964c8b3d28a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "020a51198b734d4ba693a7e906e8fee9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "585e6bdcbe32407182e861df3a2835bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4514582da26401a9836b63db0d51500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "109f5a3b45a34954a476d779b3d41a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_784836e589aa4a06990341b86443ba16",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06fa9ac27f844a3f8aa01f9584e0d50a",
              "IPY_MODEL_ffecd7eaf4f34e9d8e929f6943c025ea"
            ]
          }
        },
        "784836e589aa4a06990341b86443ba16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06fa9ac27f844a3f8aa01f9584e0d50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f0cf472f7f30474499bebced70d5875f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87311f33f9a0477fa9a17291c801475a"
          }
        },
        "ffecd7eaf4f34e9d8e929f6943c025ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f29fe31f6ea48b8adaac95d1d46b9fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 119B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8cd7438c3e754c37bc263e611f7cc2fd"
          }
        },
        "f0cf472f7f30474499bebced70d5875f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87311f33f9a0477fa9a17291c801475a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f29fe31f6ea48b8adaac95d1d46b9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8cd7438c3e754c37bc263e611f7cc2fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74bc0aa611e44985b7aab1398306bfcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56fff8650d1c4b88a52234e292ffe539",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_32def7ac70394d139c53f6294151bb2b",
              "IPY_MODEL_2e5c738d96d04faaa5741e4dd4d97f47"
            ]
          }
        },
        "56fff8650d1c4b88a52234e292ffe539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32def7ac70394d139c53f6294151bb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab078e00e03448e191ac9ff767e14806",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bb9caaeff704ab696b422c25760b353"
          }
        },
        "2e5c738d96d04faaa5741e4dd4d97f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71d46ef8475449bc9bb0fb89de64c869",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 3.80MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e542e716b9143628eedcfed2538f279"
          }
        },
        "ab078e00e03448e191ac9ff767e14806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bb9caaeff704ab696b422c25760b353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71d46ef8475449bc9bb0fb89de64c869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e542e716b9143628eedcfed2538f279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b53e87eb0e841af8d586fbe8913326e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5370c2098e8c4fe1bc1033b62521d8c0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_240efd3b6cbd4eaea1cb7bfb4e8b73be",
              "IPY_MODEL_a72620ef435c44a9a0b550716c3d29c3"
            ]
          }
        },
        "5370c2098e8c4fe1bc1033b62521d8c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "240efd3b6cbd4eaea1cb7bfb4e8b73be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_211deb28db4e47e5a9c8a2c36396c30b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_207598714bf64e48a8752aa54d24eb4a"
          }
        },
        "a72620ef435c44a9a0b550716c3d29c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7e54491210c4740b22c6f568322029f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 1.80kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ad0548707764f90b51939a332bec24c"
          }
        },
        "211deb28db4e47e5a9c8a2c36396c30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "207598714bf64e48a8752aa54d24eb4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7e54491210c4740b22c6f568322029f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ad0548707764f90b51939a332bec24c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e9fc598a00c4b32bdf2e6a496e2087d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e62c564a4ff7423d8817ca3f61a71b38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aba96a6455e34a54983aca7094b7bdfc",
              "IPY_MODEL_78074806075c4f47afee8a7f0e9b6efc"
            ]
          }
        },
        "e62c564a4ff7423d8817ca3f61a71b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aba96a6455e34a54983aca7094b7bdfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_76c2d9c30b374edaa41e6b9b7837c96b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_883f65edb46248fb95bfaba2e1b963dc"
          }
        },
        "78074806075c4f47afee8a7f0e9b6efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_80f902192b81439092b326e1e3ffc561",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:12&lt;00:00, 36.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee9c55a36a754d5aa52010072348043a"
          }
        },
        "76c2d9c30b374edaa41e6b9b7837c96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "883f65edb46248fb95bfaba2e1b963dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80f902192b81439092b326e1e3ffc561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee9c55a36a754d5aa52010072348043a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7gKgRzpwth-"
      },
      "source": [
        "# Load Pre-Trained BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0Td84cYw6-j"
      },
      "source": [
        "Install the pytorch interface for BERT by Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuHVoMkOwlGf",
        "outputId": "84dc32eb-6d6e-4692-d3b1-2f7591c524d0"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 13.9MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 17.5MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 20.1MB/s eta 0:00:01\r\u001b[K     |▌                               | 40kB 22.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 51kB 22.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 22.8MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 22.6MB/s eta 0:00:01\r\u001b[K     |█                               | 81kB 22.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 92kB 23.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 102kB 24.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 112kB 24.4MB/s eta 0:00:01\r\u001b[K     |█▋                              | 122kB 24.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 133kB 24.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 143kB 24.4MB/s eta 0:00:01\r\u001b[K     |██                              | 153kB 24.4MB/s eta 0:00:01\r\u001b[K     |██                              | 163kB 24.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 174kB 24.4MB/s eta 0:00:01\r\u001b[K     |██▍                             | 184kB 24.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 194kB 24.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 204kB 24.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 215kB 24.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 225kB 24.4MB/s eta 0:00:01\r\u001b[K     |███                             | 235kB 24.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 245kB 24.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 256kB 24.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 266kB 24.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 276kB 24.4MB/s eta 0:00:01\r\u001b[K     |███▊                            | 286kB 24.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 296kB 24.4MB/s eta 0:00:01\r\u001b[K     |████                            | 307kB 24.4MB/s eta 0:00:01\r\u001b[K     |████                            | 317kB 24.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 327kB 24.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 337kB 24.4MB/s eta 0:00:01\r\u001b[K     |████▌                           | 348kB 24.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 358kB 24.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 368kB 24.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 378kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 389kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 399kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 409kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 419kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 430kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 440kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 450kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 460kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 471kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 481kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 491kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 501kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 512kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 522kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 532kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 542kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 552kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 563kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 573kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 583kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 593kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 604kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 614kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 624kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 634kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 645kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 655kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 665kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 675kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 686kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 696kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 706kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 716kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 727kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 737kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 747kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 757kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 768kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 778kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 788kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 798kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 808kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 819kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 829kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 839kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 849kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 860kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 870kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 880kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 890kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 901kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 911kB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 921kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 931kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 942kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 952kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 962kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 972kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 983kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 993kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.6MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.6MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.6MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.6MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.6MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.6MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.6MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.6MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.6MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.6MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.7MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.7MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.7MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.7MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.7MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.7MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.7MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.7MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.7MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.8MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.8MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.8MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.8MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.8MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.8MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.8MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.8MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.8MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.8MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.9MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.9MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.9MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.9MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.9MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.9MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.9MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.9MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.9MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.9MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.0MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.1MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.2MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.3MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.4MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.5MB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.5MB 24.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 35.4MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "e939d87a13e244d79f00b20e7df1226c",
            "f24c935d459b46a79df971d59b46d2a6",
            "b37e724bd8f94c11850984955d7b36a2",
            "a49a23512fc344579b9a3a535f76ddde",
            "a5efece2d6d64d7f971964c8b3d28a84",
            "020a51198b734d4ba693a7e906e8fee9",
            "585e6bdcbe32407182e861df3a2835bc",
            "d4514582da26401a9836b63db0d51500",
            "109f5a3b45a34954a476d779b3d41a81",
            "784836e589aa4a06990341b86443ba16",
            "06fa9ac27f844a3f8aa01f9584e0d50a",
            "ffecd7eaf4f34e9d8e929f6943c025ea",
            "f0cf472f7f30474499bebced70d5875f",
            "87311f33f9a0477fa9a17291c801475a",
            "3f29fe31f6ea48b8adaac95d1d46b9fa",
            "8cd7438c3e754c37bc263e611f7cc2fd",
            "74bc0aa611e44985b7aab1398306bfcc",
            "56fff8650d1c4b88a52234e292ffe539",
            "32def7ac70394d139c53f6294151bb2b",
            "2e5c738d96d04faaa5741e4dd4d97f47",
            "ab078e00e03448e191ac9ff767e14806",
            "9bb9caaeff704ab696b422c25760b353",
            "71d46ef8475449bc9bb0fb89de64c869",
            "1e542e716b9143628eedcfed2538f279"
          ]
        },
        "id": "ZwvTKq9mxS-g",
        "outputId": "472bdc5b-284d-4cf6-e404-e7b85538b51d"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# For Logging\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# For Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e939d87a13e244d79f00b20e7df1226c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "109f5a3b45a34954a476d779b3d41a81",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74bc0aa611e44985b7aab1398306bfcc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kie3bXeRxySQ"
      },
      "source": [
        "## BERT Tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMc8wQtRIhTh"
      },
      "source": [
        "BERT provides its own tokenizer. All pre-trained tokenizer come with their own tokenizer. \n",
        "\n",
        "BERT tokenizer was created with a WordPiece model. This model greedily creates a fixed-size vocabulary of individual characters, subwords, and words that best fits our language data.\n",
        "\n",
        "This vocabulary contains four things:\n",
        "\n",
        "1. Whole words\n",
        "2. Subwords occuring at the front of a word or in isolation\n",
        "3. Subwords not at the front of a word, which are preceded by '##' to denote this case\n",
        "4. Individual characters\n",
        "\n",
        "To tokenize a word under this model, the tokenizer first checks if the whole word is in the vocabulary. If not, it tries to break the word into the largest possible subwords contained in the vocabulary, and as a last resort will decompose the word into individual characters. Because of this, we can always represent a word as, at the very least, the collection of its individual characters. No need to assign out of vocabulary words to a catch-all token like 'OOV' or 'UNK,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOQXBB6VJzhs"
      },
      "source": [
        "Break sentence into tokens with Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k-E5_I7x_dM",
        "outputId": "c55487f9-009a-47cc-906e-545b3a7b6595"
      },
      "source": [
        "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# Print out the tokens.\n",
        "print (tokenized_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-47CX1q4JvVL"
      },
      "source": [
        "After breaking the text into tokens, we then have to convert the sentence from a list of strings to a list of vocabulary indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ngSGJ7oyt-i",
        "outputId": "dfb562c6-d5d4-4bbe-d242-a5a755bcdf14"
      },
      "source": [
        "# Map the token strings to their vocabulary indices.\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "# Display the words with their indices.\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print('{} {}'.format(tup[0], tup[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 101\n",
            "after 2044\n",
            "stealing 11065\n",
            "money 2769\n",
            "from 2013\n",
            "the 1996\n",
            "bank 2924\n",
            "vault 11632\n",
            ", 1010\n",
            "the 1996\n",
            "bank 2924\n",
            "robber 27307\n",
            "was 2001\n",
            "seen 2464\n",
            "fishing 5645\n",
            "on 2006\n",
            "the 1996\n",
            "mississippi 5900\n",
            "river 2314\n",
            "bank 2924\n",
            ". 1012\n",
            "[SEP] 102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwDD6S8NzJ_8"
      },
      "source": [
        "### Segment ID\n",
        "BERT is trained on and expects sentence pairs, using 1s and 0s, to distinguish between the two sentences. \n",
        "\n",
        "If we have two sentences: we assign each word in the first sentence plus the '[SEP]' token a 0, and all tokens of the second sentence a 1.\n",
        "\n",
        "Single-sentence inputs only require a series of 1s.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz5565z90xoL",
        "outputId": "ed7a0893-c804-4f4c-9bf7-cc57cf29fb11"
      },
      "source": [
        "# Mark each of the tokens as belonging to sentence \"1\".\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "print (segments_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmjZa1sbwrsR"
      },
      "source": [
        "# Extracting Embeddings using BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PlmNpc61HMg"
      },
      "source": [
        "## Running BERT on our text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0kgEsla1Tel"
      },
      "source": [
        "The BERT PyTorch interface requires that the data be in torch tensors rather than Python lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_wAj2MY1Mbw"
      },
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipab2rGy1a5d"
      },
      "source": [
        "Calling \"from_pretrained\" will fetch the model from the internet. \n",
        "\n",
        "model.eval() puts our model in evaluation mode as opposed to training mode. It also turns off dropout regularization which is used in training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2b53e87eb0e841af8d586fbe8913326e",
            "5370c2098e8c4fe1bc1033b62521d8c0",
            "240efd3b6cbd4eaea1cb7bfb4e8b73be",
            "a72620ef435c44a9a0b550716c3d29c3",
            "211deb28db4e47e5a9c8a2c36396c30b",
            "207598714bf64e48a8752aa54d24eb4a",
            "b7e54491210c4740b22c6f568322029f",
            "8ad0548707764f90b51939a332bec24c",
            "0e9fc598a00c4b32bdf2e6a496e2087d",
            "e62c564a4ff7423d8817ca3f61a71b38",
            "aba96a6455e34a54983aca7094b7bdfc",
            "78074806075c4f47afee8a7f0e9b6efc",
            "76c2d9c30b374edaa41e6b9b7837c96b",
            "883f65edb46248fb95bfaba2e1b963dc",
            "80f902192b81439092b326e1e3ffc561",
            "ee9c55a36a754d5aa52010072348043a"
          ]
        },
        "id": "K2zCEkr61jsi",
        "outputId": "8a75da52-b207-4b1f-cc51-598d2f5a7f1a"
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b53e87eb0e841af8d586fbe8913326e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e9fc598a00c4b32bdf2e6a496e2087d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD5QeL5A2q0e"
      },
      "source": [
        "Evaluate BERT on our example text, and fetch the hidden states of the network.\n",
        "\n",
        "`torch.no_grad` tells PyTorch not to construct the compute graph during this forward pass (since we won't be running backprop here). It just reduces memory consumption and speeds things up a little.\n",
        "\n",
        "Note: Evaluating the model will return a different number of objects based on how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "becase we set `output_hidden_states = True`, the third item will be the hidden states from all layers. (Ref: https://huggingface.co/transformers/model_doc/bert.html#bertmodel )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfjgkQAE2SMR"
      },
      "source": [
        "# Run the text through BERT, and collect all of the hidden states produced\n",
        "# from all 12 layers. \n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "\n",
        "    \n",
        "    hidden_states = outputs[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yybtuJpElpL",
        "outputId": "0bcf06ae-0d0a-47c5-d746-6445e44524d3"
      },
      "source": [
        "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))\n",
        "\n",
        "# 'hidden_states' is a Python list.\n",
        "print('Type of hidden_states: ', type(hidden_states))\n",
        "\n",
        "# Each layer in the list is a torch tensor.\n",
        "print('Tensor shape for each layer: ', hidden_states[0].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
            "Number of batches: 1\n",
            "Number of tokens: 22\n",
            "Number of hidden units: 768\n",
            "      Type of hidden_states:  <class 'tuple'>\n",
            "Tensor shape for each layer:  torch.Size([1, 22, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU4w0E4fEmkG"
      },
      "source": [
        "## Get Token Embeddings from hidden states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlJjUjEqEm86",
        "outputId": "ea57286f-6545-4434-a0b1-5dc03b5e279f"
      },
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 1, 22, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWwn_88PFaw0",
        "outputId": "f36c6d23-a0bb-4700-d58b-bf8e32b80eec"
      },
      "source": [
        "# Remove dimension 1, the \"batches\" (not needed)\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 22, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtotEHKzFoBs",
        "outputId": "5c5f5d32-a683-42ef-cc74-31a365584acc"
      },
      "source": [
        "# Swap dimensions 0 and 1.\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([22, 13, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi4yuHulFtUs"
      },
      "source": [
        "## Creating word and sentence vectors from hidden states\n",
        "\n",
        "We want to get individual vectors for each of our tokens, or a single vector representation of the whole sentence\n",
        "\n",
        "Given above, for each token of our input we have 13 separate vectors each of length 768. In order to get the individual vectors we will need to combine some of the layer vectors.\n",
        "\n",
        "But which layer or combination of layers provides the best representation? \n",
        "There's no single easy answer. We can try a couple reasonable approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RruFwq_AHIXg"
      },
      "source": [
        "### Word Vectors\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Glb-kDsnHP5K"
      },
      "source": [
        "Approach A: **concatenate** \n",
        "\n",
        "Concatenate the last four (or n) layers, giving us a single word vector per token. Each vector will have length `4 x 768 = 3,072`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLVU9bpKGzHq",
        "outputId": "70388455-024d-48c9-a508-5af0949cae83"
      },
      "source": [
        "# Stores the token vectors, with shape [22 x 3,072]\n",
        "token_vecs_cat = []\n",
        "\n",
        "# 'token_embeddings' is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "    \n",
        "    # 'token' is a [12 x 768] tensor\n",
        "\n",
        "    # Concatenate the vectors (append them together) from the last four layers.\n",
        "    # Each layer vector is 768 values, so 'cat_vec' is length 3,072.\n",
        "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "    \n",
        "    # Use 'cat_vec' to represent `token`.\n",
        "    token_vecs_cat.append(cat_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is: 22 x 3072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld42Ob8cGytb"
      },
      "source": [
        "Approach B: **summing** \n",
        "\n",
        "Create the word vectors by summing together the last four (or n) layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGNLu1tPIJ2x",
        "outputId": "d06034bb-5286-4f9b-bda2-67146c7387cd"
      },
      "source": [
        "# Stores the token vectors, with shape [22 x 768]\n",
        "token_vecs_sum = []\n",
        "\n",
        "# 'token_embeddings' is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # 'token' is a [12 x 768] tensor\n",
        "\n",
        "    # Sum the vectors from the last four layers.\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "    \n",
        "    # Use 'sum_vec' to represent `token`.\n",
        "    token_vecs_sum.append(sum_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is: 22 x 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT0SxNXuGoMQ"
      },
      "source": [
        "### Sentence Vectors\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpdI1Ykp3gzl"
      },
      "source": [
        "To get a single vector for our entire sentence we have multiple application-dependent strategies.\n",
        "\n",
        "A simple approach is to average the second to last hiden layer of each token producing a single 768 length vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UIWbtl-KPNJ",
        "outputId": "41f05f98-8563-42c5-dd90-55f87d9f2dbd"
      },
      "source": [
        "# 'hidden_states' has shape [13 x 1 x 22 x 768]\n",
        "\n",
        "# 'token_vecs' is a tensor with shape [22 x 768]\n",
        "token_vecs = hidden_states[-2][0]\n",
        "\n",
        "# Calculate the average of all 22 token vectors.\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "\n",
        "print (\"Final sentence embedding vector has shape:\", sentence_embedding.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final sentence embedding vector has shape: torch.Size([768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvN9tGXwKde0"
      },
      "source": [
        "## Confirming contextually dependent vectors\n",
        "\n",
        "To confirm that the value of these vectors are in fact contextually dependent, let's look at the different instances of the word \"bank\" in our example sentence:\n",
        "\n",
        "\"After stealing money from the **bank vault**, the **bank robber** was seen fishing on the Mississippi **river bank**.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyla6NfBLElG",
        "outputId": "77baa90d-3090-4e81-d978-b38c4634e824"
      },
      "source": [
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print (i, token_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 after\n",
            "2 stealing\n",
            "3 money\n",
            "4 from\n",
            "5 the\n",
            "6 bank\n",
            "7 vault\n",
            "8 ,\n",
            "9 the\n",
            "10 bank\n",
            "11 robber\n",
            "12 was\n",
            "13 seen\n",
            "14 fishing\n",
            "15 on\n",
            "16 the\n",
            "17 mississippi\n",
            "18 river\n",
            "19 bank\n",
            "20 .\n",
            "21 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNhxT_ECLATC"
      },
      "source": [
        "They are at 6, 10, and 19.\n",
        "\n",
        "For this analysis, let's use the word vectors that we created by summing the last four layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RhKdGTWLTpN",
        "outputId": "680634c5-67df-4d2d-ae2c-dc41c4dceb24"
      },
      "source": [
        "print('First 5 vector values for each instance of \"bank\".')\n",
        "print('')\n",
        "print(\"bank vault   \", str(token_vecs_sum[6][:5]))\n",
        "print(\"bank robber  \", str(token_vecs_sum[10][:5]))\n",
        "print(\"river bank   \", str(token_vecs_sum[19][:5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 5 vector values for each instance of \"bank\".\n",
            "\n",
            "bank vault    tensor([ 3.3596, -2.9805, -1.5421,  0.7065,  2.0031])\n",
            "bank robber   tensor([ 2.7359, -2.5577, -1.3094,  0.6797,  1.6633])\n",
            "river bank    tensor([ 1.5266, -0.8895, -0.5152, -0.9298,  2.8334])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jr8LoUfLbmB"
      },
      "source": [
        "The vector values in each case differ, but let's calculate the cosine similarity between the vectors to make a more precise comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2LD5_mRLcHw",
        "outputId": "390dc4f2-52dc-4f8d-e9ee-a332bcc4a8e3"
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Calculate the cosine similarity between the word bank\n",
        "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
        "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
        "\n",
        "# Calculate the cosine similarity between the word bank \n",
        "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
        "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
        "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector similarity for  *similar*  meanings:  0.94\n",
            "Vector similarity for *different* meanings:  0.69\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}